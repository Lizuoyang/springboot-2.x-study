spring:
  # kafka的配置项，对应KafkaProperties 配置类
  kafka:
    # 配置kafka的broker地址，可以设置多个，以逗号分隔
    bootstrap-servers: 81.71.68.248:9092
    # kafka producer 配置项
    producer:
      # 0-不应答，1-leader应答，all-所有的leader和follower应答
      acks: 1
      # 配置发送失败重试次数
      retries: 3
      # 配置消息key的序列化方式(string)
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 配置消息value的序列化方式(json)
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      # 每次批量发送的最大消息量 16*1024
      #batch-size: 16384
      # 每次批量发送消息的最大内存
      #buffer-memory: 33554432
      # 每次批量发送消息的超时时间，延迟时间上限，配置为 30 * 1000ms过后，不管是否消息输两是否达到batch-size或者消息大小达到buffer-memory后，都会直接发起一次请求
      #properties:
      #  linger:
      #    ms: 30000
    # kafka customer 配置项
    consumer:
      # 设置消费者分组最初的消费进度为 earliest，当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费。
      auto-offset-reset: earliest
      # 配置消息key的反序列化方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 配置消息value的反序列化方式
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      # poll 一次拉取的阻塞的最大时长，单位：毫秒。这里指的是阻塞拉取需要满足至少 fetch-min-size 大小的消息
      #fetch-max-wait: 10000
      # poll 一次消息拉取的最小数据量，单位：字节
      #fetch-min-size: 10
      # poll 一次消息拉取的最大数量
      #max-poll-records: 100
      properties:
        spring:
          json:
            trusted:
              packages: com.lizuoyang.springboot.message
    # 配置kafka consumer listener 监听器
    listener:
      # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
      missing-topics-fatal: false
      # 监听器类型，默认为 SINGLE ，只监听单条消息。这里我们配置 BATCH ，监听多条消息，批量消费
      type: batch

# 配置日志打印级别，避免无用日志太多
logging:
  level:
    org:
      springframework:
        kafka: error
      apache:
        kafka: error
